[ DATADIR ]  ./data/Fish
[ AUGMENT ] [resize] 512 [sift] circle [edge] None [gabor] None [perspective] None
[ DATASET ] [train] n:9, size:258 [val] n:9, size:86 [test] n:9, size:86
[ NETWORK ] [backbone] resnet18 [n_cv] 1 [gabor] None
[ DEVICE  ] CUDA available
[OPTIMIZER] ADAM FIXED [LearningRate]  5e-05

====================== TRAINING START! =====================
[Epoch 1/100] [TRAIN] Loss: 2.1635 Acc: 0.1744
[Epoch 2/100] [TRAIN] Loss: 1.9684 Acc: 0.3760
[Epoch 3/100] [TRAIN] Loss: 1.7291 Acc: 0.4070
[Epoch 4/100] [TRAIN] Loss: 1.5529 Acc: 0.5039
[Epoch 5/100] [TRAIN] Loss: 1.4260 Acc: 0.5078 [VAL] Loss: 2.7657 Acc: 0.1860
[Epoch 6/100] [TRAIN] Loss: 1.3155 Acc: 0.5698
[Epoch 7/100] [TRAIN] Loss: 1.2282 Acc: 0.6589
[Epoch 8/100] [TRAIN] Loss: 1.1541 Acc: 0.6667
[Epoch 9/100] [TRAIN] Loss: 1.1066 Acc: 0.6550
[Epoch 10/100] [TRAIN] Loss: 1.0500 Acc: 0.7403 [VAL] Loss: 1.4927 Acc: 0.4884
[Epoch 11/100] [TRAIN] Loss: 0.9699 Acc: 0.7829
[Epoch 12/100] [TRAIN] Loss: 0.9156 Acc: 0.7558
[Epoch 13/100] [TRAIN] Loss: 0.8624 Acc: 0.8295
[Epoch 14/100] [TRAIN] Loss: 0.8072 Acc: 0.8101
[Epoch 15/100] [TRAIN] Loss: 0.8420 Acc: 0.8217 [VAL] Loss: 1.2565 Acc: 0.5581
[Epoch 16/100] [TRAIN] Loss: 0.7404 Acc: 0.8488
[Epoch 17/100] [TRAIN] Loss: 0.6583 Acc: 0.8798
[Epoch 18/100] [TRAIN] Loss: 0.6228 Acc: 0.9109
[Epoch 19/100] [TRAIN] Loss: 0.5871 Acc: 0.8953
[Epoch 20/100] [TRAIN] Loss: 0.5911 Acc: 0.9031 [VAL] Loss: 0.9521 Acc: 0.6395
[Epoch 21/100] [TRAIN] Loss: 0.5395 Acc: 0.9264
[Epoch 22/100] [TRAIN] Loss: 0.5074 Acc: 0.9302
[Epoch 23/100] [TRAIN] Loss: 0.4835 Acc: 0.9225
[Epoch 24/100] [TRAIN] Loss: 0.4614 Acc: 0.9302
[Epoch 25/100] [TRAIN] Loss: 0.4667 Acc: 0.9225 [VAL] Loss: 0.9778 Acc: 0.6977
[Epoch 26/100] [TRAIN] Loss: 0.3750 Acc: 0.9612
[Epoch 27/100] [TRAIN] Loss: 0.3852 Acc: 0.9496
[Epoch 28/100] [TRAIN] Loss: 0.4121 Acc: 0.9341
[Epoch 29/100] [TRAIN] Loss: 0.4007 Acc: 0.9380
[Epoch 30/100] [TRAIN] Loss: 0.3361 Acc: 0.9651 [VAL] Loss: 0.8279 Acc: 0.7558
[Epoch 31/100] [TRAIN] Loss: 0.3369 Acc: 0.9535
[Epoch 32/100] [TRAIN] Loss: 0.3387 Acc: 0.9419
[Epoch 33/100] [TRAIN] Loss: 0.2912 Acc: 0.9729
[Epoch 34/100] [TRAIN] Loss: 0.3402 Acc: 0.9380
[Epoch 35/100] [TRAIN] Loss: 0.2986 Acc: 0.9729 [VAL] Loss: 0.7979 Acc: 0.7558
[Epoch 36/100] [TRAIN] Loss: 0.3211 Acc: 0.9419
[Epoch 37/100] [TRAIN] Loss: 0.2948 Acc: 0.9341
[Epoch 38/100] [TRAIN] Loss: 0.3058 Acc: 0.9612
[Epoch 39/100] [TRAIN] Loss: 0.2711 Acc: 0.9690
[Epoch 40/100] [TRAIN] Loss: 0.3446 Acc: 0.9341 [VAL] Loss: 1.0895 Acc: 0.6395
[Epoch 41/100] [TRAIN] Loss: 0.2680 Acc: 0.9574
[Epoch 42/100] [TRAIN] Loss: 0.3037 Acc: 0.9341
[Epoch 43/100] [TRAIN] Loss: 0.2459 Acc: 0.9729
[Epoch 44/100] [TRAIN] Loss: 0.2009 Acc: 0.9767
[Epoch 45/100] [TRAIN] Loss: 0.1998 Acc: 0.9845 [VAL] Loss: 0.8391 Acc: 0.8023
[Epoch 46/100] [TRAIN] Loss: 0.1917 Acc: 0.9690
[Epoch 47/100] [TRAIN] Loss: 0.1845 Acc: 0.9845
[Epoch 48/100] [TRAIN] Loss: 0.1717 Acc: 0.9922
[Epoch 49/100] [TRAIN] Loss: 0.1569 Acc: 0.9922
[Epoch 50/100] [TRAIN] Loss: 0.1815 Acc: 0.9767 [VAL] Loss: 1.1209 Acc: 0.7093
[Epoch 51/100] [TRAIN] Loss: 0.1889 Acc: 0.9884
[Epoch 52/100] [TRAIN] Loss: 0.2179 Acc: 0.9690
[Epoch 53/100] [TRAIN] Loss: 0.2004 Acc: 0.9496
[Epoch 54/100] [TRAIN] Loss: 0.1857 Acc: 0.9806
[Epoch 55/100] [TRAIN] Loss: 0.1909 Acc: 0.9806 [VAL] Loss: 0.8663 Acc: 0.6977
[Epoch 56/100] [TRAIN] Loss: 0.1697 Acc: 0.9806
[Epoch 57/100] [TRAIN] Loss: 0.2415 Acc: 0.9419
[Epoch 58/100] [TRAIN] Loss: 0.1685 Acc: 0.9690
[Epoch 59/100] [TRAIN] Loss: 0.1698 Acc: 0.9845
[Epoch 60/100] [TRAIN] Loss: 0.2074 Acc: 0.9806 [VAL] Loss: 0.8401 Acc: 0.6977
[Epoch 61/100] [TRAIN] Loss: 0.1944 Acc: 0.9729
[Epoch 62/100] [TRAIN] Loss: 0.2172 Acc: 0.9690
[Epoch 63/100] [TRAIN] Loss: 0.1693 Acc: 0.9767
[Epoch 64/100] [TRAIN] Loss: 0.1505 Acc: 0.9884
[Epoch 65/100] [TRAIN] Loss: 0.1569 Acc: 0.9806 [VAL] Loss: 0.6738 Acc: 0.7674
[Epoch 66/100] [TRAIN] Loss: 0.1304 Acc: 0.9884
[Epoch 67/100] [TRAIN] Loss: 0.1394 Acc: 0.9922
[Epoch 68/100] [TRAIN] Loss: 0.1040 Acc: 0.9922
[Epoch 69/100] [TRAIN] Loss: 0.1239 Acc: 0.9884
[Epoch 70/100] [TRAIN] Loss: 0.1284 Acc: 0.9845 [VAL] Loss: 0.6991 Acc: 0.7791
[Epoch 71/100] [TRAIN] Loss: 0.1240 Acc: 0.9845
[Epoch 72/100] [TRAIN] Loss: 0.1350 Acc: 0.9729
[Epoch 73/100] [TRAIN] Loss: 0.1322 Acc: 0.9884
[Epoch 74/100] [TRAIN] Loss: 0.1257 Acc: 0.9961
[Epoch 75/100] [TRAIN] Loss: 0.1214 Acc: 0.9961 [VAL] Loss: 1.2470 Acc: 0.6628
[Epoch 76/100] [TRAIN] Loss: 0.1290 Acc: 0.9806
[Epoch 77/100] [TRAIN] Loss: 0.1327 Acc: 0.9845
[Epoch 78/100] [TRAIN] Loss: 0.1297 Acc: 0.9884
[Epoch 79/100] [TRAIN] Loss: 0.1068 Acc: 0.9884
[Epoch 80/100] [TRAIN] Loss: 0.1369 Acc: 0.9845 [VAL] Loss: 0.7672 Acc: 0.7442
[Epoch 81/100] [TRAIN] Loss: 0.1155 Acc: 0.9884
[Epoch 82/100] [TRAIN] Loss: 0.1151 Acc: 0.9845
[Epoch 83/100] [TRAIN] Loss: 0.1070 Acc: 0.9922
[Epoch 84/100] [TRAIN] Loss: 0.0875 Acc: 0.9922
[Epoch 85/100] [TRAIN] Loss: 0.1259 Acc: 0.9729 [VAL] Loss: 1.2643 Acc: 0.6744
[Epoch 86/100] [TRAIN] Loss: 0.0968 Acc: 0.9922
[Epoch 87/100] [TRAIN] Loss: 0.0940 Acc: 1.0000
[Epoch 88/100] [TRAIN] Loss: 0.0961 Acc: 0.9884
[Epoch 89/100] [TRAIN] Loss: 0.0969 Acc: 0.9961
[Epoch 90/100] [TRAIN] Loss: 0.1011 Acc: 0.9845 [VAL] Loss: 0.7924 Acc: 0.7209
[Epoch 91/100] [TRAIN] Loss: 0.0847 Acc: 0.9961
[Epoch 92/100] [TRAIN] Loss: 0.0756 Acc: 0.9961
[Epoch 93/100] [TRAIN] Loss: 0.0728 Acc: 1.0000
[Epoch 94/100] [TRAIN] Loss: 0.0749 Acc: 0.9922
[Epoch 95/100] [TRAIN] Loss: 0.0850 Acc: 0.9922 [VAL] Loss: 0.7630 Acc: 0.7907
[Epoch 96/100] [TRAIN] Loss: 0.0860 Acc: 0.9884
[Epoch 97/100] [TRAIN] Loss: 0.0958 Acc: 0.9845
[Epoch 98/100] [TRAIN] Loss: 0.0660 Acc: 0.9961
[Epoch 99/100] [TRAIN] Loss: 0.0829 Acc: 0.9961
[Epoch 100/100] [TRAIN] Loss: 0.0643 Acc: 1.0000 [VAL] Loss: 0.8791 Acc: 0.7209
[TEST] Loss: 0.6494 Acc: 0.7558
===================== TRAINING FINISH! ====================

############################################################
#                                                          #
#                  Test Accuracy : 0.7558                  #
#                                                          #
############################################################

