[ DATADIR ]  ./data/Fish
[ AUGMENT ] [resize] 512 [sift] None [edge] None [gabor] None [perspective] None
[ DATASET ] [train] n:9, size:258 [val] n:9, size:86 [test] n:9, size:86
[ NETWORK ] [backbone] resnet18 [n_cv] 0 [gabor] True
[ DEVICE  ] CUDA available
[OPTIMIZER] ADAM FIXED [LearningRate]  5e-05

====================== TRAINING START! =====================
[Epoch 1/100] [TRAIN] Loss: 2.1241 Acc: 0.2132
[Epoch 2/100] [TRAIN] Loss: 1.9462 Acc: 0.3062
[Epoch 3/100] [TRAIN] Loss: 1.8711 Acc: 0.3333
[Epoch 4/100] [TRAIN] Loss: 1.8026 Acc: 0.3372
[Epoch 5/100] [TRAIN] Loss: 1.7666 Acc: 0.3488 [VAL] Loss: 1.7565 Acc: 0.3140
[Epoch 6/100] [TRAIN] Loss: 1.7234 Acc: 0.3527
[Epoch 7/100] [TRAIN] Loss: 1.6862 Acc: 0.3953
[Epoch 8/100] [TRAIN] Loss: 1.6803 Acc: 0.4457
[Epoch 9/100] [TRAIN] Loss: 1.6341 Acc: 0.4574
[Epoch 10/100] [TRAIN] Loss: 1.5948 Acc: 0.4806 [VAL] Loss: 1.6877 Acc: 0.3721
[Epoch 11/100] [TRAIN] Loss: 1.5793 Acc: 0.4845
[Epoch 12/100] [TRAIN] Loss: 1.5450 Acc: 0.5233
[Epoch 13/100] [TRAIN] Loss: 1.5436 Acc: 0.5581
[Epoch 14/100] [TRAIN] Loss: 1.5342 Acc: 0.5620
[Epoch 15/100] [TRAIN] Loss: 1.4722 Acc: 0.5969 [VAL] Loss: 1.6118 Acc: 0.4651
[Epoch 16/100] [TRAIN] Loss: 1.4571 Acc: 0.5891
[Epoch 17/100] [TRAIN] Loss: 1.4513 Acc: 0.6008
[Epoch 18/100] [TRAIN] Loss: 1.4192 Acc: 0.6085
[Epoch 19/100] [TRAIN] Loss: 1.4010 Acc: 0.6085
[Epoch 20/100] [TRAIN] Loss: 1.4330 Acc: 0.6395 [VAL] Loss: 1.6342 Acc: 0.3837
[Epoch 21/100] [TRAIN] Loss: 1.3750 Acc: 0.6279
[Epoch 22/100] [TRAIN] Loss: 1.3561 Acc: 0.6202
[Epoch 23/100] [TRAIN] Loss: 1.3515 Acc: 0.6589
[Epoch 24/100] [TRAIN] Loss: 1.3238 Acc: 0.6240
[Epoch 25/100] [TRAIN] Loss: 1.3168 Acc: 0.6667 [VAL] Loss: 1.6064 Acc: 0.5116
[Epoch 26/100] [TRAIN] Loss: 1.2944 Acc: 0.6705
[Epoch 27/100] [TRAIN] Loss: 1.2878 Acc: 0.6667
[Epoch 28/100] [TRAIN] Loss: 1.2803 Acc: 0.6783
[Epoch 29/100] [TRAIN] Loss: 1.2679 Acc: 0.6783
[Epoch 30/100] [TRAIN] Loss: 1.2608 Acc: 0.6783 [VAL] Loss: 2.9755 Acc: 0.2442
[Epoch 31/100] [TRAIN] Loss: 1.2356 Acc: 0.6744
[Epoch 32/100] [TRAIN] Loss: 1.2053 Acc: 0.6860
[Epoch 33/100] [TRAIN] Loss: 1.1885 Acc: 0.6938
[Epoch 34/100] [TRAIN] Loss: 1.1969 Acc: 0.7016
[Epoch 35/100] [TRAIN] Loss: 1.1729 Acc: 0.7132 [VAL] Loss: 1.4490 Acc: 0.5000
[Epoch 36/100] [TRAIN] Loss: 1.1765 Acc: 0.6938
[Epoch 37/100] [TRAIN] Loss: 1.1359 Acc: 0.7171
[Epoch 38/100] [TRAIN] Loss: 1.0951 Acc: 0.7364
[Epoch 39/100] [TRAIN] Loss: 1.1698 Acc: 0.7054
[Epoch 40/100] [TRAIN] Loss: 1.1149 Acc: 0.7016 [VAL] Loss: 3.6158 Acc: 0.2442
[Epoch 41/100] [TRAIN] Loss: 1.1301 Acc: 0.7326
[Epoch 42/100] [TRAIN] Loss: 1.0820 Acc: 0.7364
[Epoch 43/100] [TRAIN] Loss: 1.0588 Acc: 0.7519
[Epoch 44/100] [TRAIN] Loss: 1.0831 Acc: 0.7132
[Epoch 45/100] [TRAIN] Loss: 1.0241 Acc: 0.7674 [VAL] Loss: 2.5743 Acc: 0.3023
[Epoch 46/100] [TRAIN] Loss: 1.0484 Acc: 0.7364
[Epoch 47/100] [TRAIN] Loss: 1.0368 Acc: 0.7403
[Epoch 48/100] [TRAIN] Loss: 1.0076 Acc: 0.7868
[Epoch 49/100] [TRAIN] Loss: 0.9897 Acc: 0.8101
[Epoch 50/100] [TRAIN] Loss: 0.9854 Acc: 0.7636 [VAL] Loss: 1.3922 Acc: 0.5349
[Epoch 51/100] [TRAIN] Loss: 0.9627 Acc: 0.7713
[Epoch 52/100] [TRAIN] Loss: 0.9421 Acc: 0.7907
[Epoch 53/100] [TRAIN] Loss: 0.9269 Acc: 0.7946
[Epoch 54/100] [TRAIN] Loss: 0.9068 Acc: 0.7907
[Epoch 55/100] [TRAIN] Loss: 0.9081 Acc: 0.8023 [VAL] Loss: 2.3452 Acc: 0.3256
[Epoch 56/100] [TRAIN] Loss: 0.9197 Acc: 0.7907
[Epoch 57/100] [TRAIN] Loss: 0.8880 Acc: 0.8101
[Epoch 58/100] [TRAIN] Loss: 1.0134 Acc: 0.7132
[Epoch 59/100] [TRAIN] Loss: 0.9447 Acc: 0.8062
[Epoch 60/100] [TRAIN] Loss: 0.8934 Acc: 0.7984 [VAL] Loss: 1.7203 Acc: 0.3488
[Epoch 61/100] [TRAIN] Loss: 0.8553 Acc: 0.8450
[Epoch 62/100] [TRAIN] Loss: 0.8312 Acc: 0.8256
[Epoch 63/100] [TRAIN] Loss: 0.8274 Acc: 0.8488
[Epoch 64/100] [TRAIN] Loss: 0.8202 Acc: 0.8295
[Epoch 65/100] [TRAIN] Loss: 0.8144 Acc: 0.8295 [VAL] Loss: 2.4610 Acc: 0.2093
[Epoch 66/100] [TRAIN] Loss: 0.8270 Acc: 0.8411
[Epoch 67/100] [TRAIN] Loss: 0.7928 Acc: 0.8295
[Epoch 68/100] [TRAIN] Loss: 0.7900 Acc: 0.8217
[Epoch 69/100] [TRAIN] Loss: 0.7888 Acc: 0.8333
[Epoch 70/100] [TRAIN] Loss: 0.8033 Acc: 0.8217 [VAL] Loss: 1.7597 Acc: 0.3837
[Epoch 71/100] [TRAIN] Loss: 0.7614 Acc: 0.8488
[Epoch 72/100] [TRAIN] Loss: 0.7691 Acc: 0.8915
[Epoch 73/100] [TRAIN] Loss: 0.7691 Acc: 0.8101
[Epoch 74/100] [TRAIN] Loss: 0.7801 Acc: 0.8450
[Epoch 75/100] [TRAIN] Loss: 0.7357 Acc: 0.8721 [VAL] Loss: 10.4320 Acc: 0.0930
[Epoch 76/100] [TRAIN] Loss: 0.7148 Acc: 0.8837
[Epoch 77/100] [TRAIN] Loss: 0.6649 Acc: 0.8798
[Epoch 78/100] [TRAIN] Loss: 0.6867 Acc: 0.8682
[Epoch 79/100] [TRAIN] Loss: 0.6661 Acc: 0.8876
[Epoch 80/100] [TRAIN] Loss: 0.6887 Acc: 0.8876 [VAL] Loss: 1.2254 Acc: 0.6163
[Epoch 81/100] [TRAIN] Loss: 0.6692 Acc: 0.9186
[Epoch 82/100] [TRAIN] Loss: 0.6776 Acc: 0.8798
[Epoch 83/100] [TRAIN] Loss: 0.6578 Acc: 0.9031
[Epoch 84/100] [TRAIN] Loss: 0.6458 Acc: 0.8643
[Epoch 85/100] [TRAIN] Loss: 0.6226 Acc: 0.8876 [VAL] Loss: 1.5300 Acc: 0.4884
[Epoch 86/100] [TRAIN] Loss: 0.6200 Acc: 0.9070
[Epoch 87/100] [TRAIN] Loss: 0.6508 Acc: 0.8643
[Epoch 88/100] [TRAIN] Loss: 0.6585 Acc: 0.8992
[Epoch 89/100] [TRAIN] Loss: 0.5939 Acc: 0.9109
[Epoch 90/100] [TRAIN] Loss: 0.5878 Acc: 0.9109 [VAL] Loss: 1.1204 Acc: 0.6512
[Epoch 91/100] [TRAIN] Loss: 0.5753 Acc: 0.9031
[Epoch 92/100] [TRAIN] Loss: 0.5941 Acc: 0.9070
[Epoch 93/100] [TRAIN] Loss: 0.5967 Acc: 0.8915
[Epoch 94/100] [TRAIN] Loss: 0.6786 Acc: 0.8527
[Epoch 95/100] [TRAIN] Loss: 0.5974 Acc: 0.9109 [VAL] Loss: 5.7769 Acc: 0.2093
[Epoch 96/100] [TRAIN] Loss: 0.6050 Acc: 0.8953
[Epoch 97/100] [TRAIN] Loss: 0.5605 Acc: 0.9186
[Epoch 98/100] [TRAIN] Loss: 0.5595 Acc: 0.9225
[Epoch 99/100] [TRAIN] Loss: 0.5215 Acc: 0.9496
[Epoch 100/100] [TRAIN] Loss: 0.5263 Acc: 0.9264 [VAL] Loss: 1.0892 Acc: 0.6163
[TEST] Loss: 1.2241 Acc: 0.6279
===================== TRAINING FINISH! ====================

############################################################
#                                                          #
#                  Test Accuracy : 0.6279                  #
#                                                          #
############################################################

