[ DATADIR ]  ./data/Fish
[ AUGMENT ] [resize] 512 [sift] None [edge] None [gabor] None [perspective] None
[ DATASET ] [train] n:9, size:258 [val] n:9, size:86 [test] n:9, size:86
[ NETWORK ] [backbone] resnet18 [n_cv] 0 [gabor] None
[ DEVICE  ] CUDA available
[OPTIMIZER] ADAM FIXED [LearningRate]  5e-05

====================== TRAINING START! =====================
[Epoch 1/100] [TRAIN] Loss: 2.1653 Acc: 0.2054
[Epoch 2/100] [TRAIN] Loss: 1.9296 Acc: 0.3798
[Epoch 3/100] [TRAIN] Loss: 1.7368 Acc: 0.3837
[Epoch 4/100] [TRAIN] Loss: 1.5681 Acc: 0.4496
[Epoch 5/100] [TRAIN] Loss: 1.4579 Acc: 0.5233 [VAL] Loss: 2.5564 Acc: 0.1163
[Epoch 6/100] [TRAIN] Loss: 1.3518 Acc: 0.5853
[Epoch 7/100] [TRAIN] Loss: 1.2617 Acc: 0.6047
[Epoch 8/100] [TRAIN] Loss: 1.1900 Acc: 0.6589
[Epoch 9/100] [TRAIN] Loss: 1.1364 Acc: 0.6628
[Epoch 10/100] [TRAIN] Loss: 1.0508 Acc: 0.6705 [VAL] Loss: 1.2549 Acc: 0.5581
[Epoch 11/100] [TRAIN] Loss: 1.0186 Acc: 0.6860
[Epoch 12/100] [TRAIN] Loss: 0.9361 Acc: 0.7558
[Epoch 13/100] [TRAIN] Loss: 0.9092 Acc: 0.7829
[Epoch 14/100] [TRAIN] Loss: 0.8330 Acc: 0.8217
[Epoch 15/100] [TRAIN] Loss: 0.8390 Acc: 0.8295 [VAL] Loss: 1.1864 Acc: 0.6047
[Epoch 16/100] [TRAIN] Loss: 0.7578 Acc: 0.8566
[Epoch 17/100] [TRAIN] Loss: 0.7178 Acc: 0.8450
[Epoch 18/100] [TRAIN] Loss: 0.6756 Acc: 0.8643
[Epoch 19/100] [TRAIN] Loss: 0.6755 Acc: 0.8837
[Epoch 20/100] [TRAIN] Loss: 0.6226 Acc: 0.8721 [VAL] Loss: 1.1821 Acc: 0.6163
[Epoch 21/100] [TRAIN] Loss: 0.5955 Acc: 0.8953
[Epoch 22/100] [TRAIN] Loss: 0.5449 Acc: 0.9380
[Epoch 23/100] [TRAIN] Loss: 0.5094 Acc: 0.9147
[Epoch 24/100] [TRAIN] Loss: 0.4814 Acc: 0.9225
[Epoch 25/100] [TRAIN] Loss: 0.4979 Acc: 0.9225 [VAL] Loss: 0.8837 Acc: 0.7093
[Epoch 26/100] [TRAIN] Loss: 0.4166 Acc: 0.9690
[Epoch 27/100] [TRAIN] Loss: 0.4752 Acc: 0.9109
[Epoch 28/100] [TRAIN] Loss: 0.4097 Acc: 0.9302
[Epoch 29/100] [TRAIN] Loss: 0.4129 Acc: 0.9341
[Epoch 30/100] [TRAIN] Loss: 0.4183 Acc: 0.9341 [VAL] Loss: 0.9665 Acc: 0.6628
[Epoch 31/100] [TRAIN] Loss: 0.3806 Acc: 0.9341
[Epoch 32/100] [TRAIN] Loss: 0.3353 Acc: 0.9690
[Epoch 33/100] [TRAIN] Loss: 0.3746 Acc: 0.9419
[Epoch 34/100] [TRAIN] Loss: 0.3152 Acc: 0.9729
[Epoch 35/100] [TRAIN] Loss: 0.3159 Acc: 0.9612 [VAL] Loss: 0.8448 Acc: 0.7442
[Epoch 36/100] [TRAIN] Loss: 0.2700 Acc: 0.9884
[Epoch 37/100] [TRAIN] Loss: 0.2591 Acc: 0.9884
[Epoch 38/100] [TRAIN] Loss: 0.2622 Acc: 0.9651
[Epoch 39/100] [TRAIN] Loss: 0.3000 Acc: 0.9574
[Epoch 40/100] [TRAIN] Loss: 0.3025 Acc: 0.9612 [VAL] Loss: 0.8332 Acc: 0.6744
[Epoch 41/100] [TRAIN] Loss: 0.2341 Acc: 0.9845
[Epoch 42/100] [TRAIN] Loss: 0.2530 Acc: 0.9806
[Epoch 43/100] [TRAIN] Loss: 0.2728 Acc: 0.9612
[Epoch 44/100] [TRAIN] Loss: 0.2450 Acc: 0.9767
[Epoch 45/100] [TRAIN] Loss: 0.2539 Acc: 0.9767 [VAL] Loss: 0.5982 Acc: 0.8256
[Epoch 46/100] [TRAIN] Loss: 0.2436 Acc: 0.9690
[Epoch 47/100] [TRAIN] Loss: 0.2796 Acc: 0.9496
[Epoch 48/100] [TRAIN] Loss: 0.2366 Acc: 0.9690
[Epoch 49/100] [TRAIN] Loss: 0.1850 Acc: 0.9961
[Epoch 50/100] [TRAIN] Loss: 0.1974 Acc: 0.9651 [VAL] Loss: 0.7230 Acc: 0.8023
[Epoch 51/100] [TRAIN] Loss: 0.2131 Acc: 0.9806
[Epoch 52/100] [TRAIN] Loss: 0.2371 Acc: 0.9767
[Epoch 53/100] [TRAIN] Loss: 0.2160 Acc: 0.9690
[Epoch 54/100] [TRAIN] Loss: 0.2039 Acc: 0.9845
[Epoch 55/100] [TRAIN] Loss: 0.2065 Acc: 0.9574 [VAL] Loss: 0.7979 Acc: 0.7326
[Epoch 56/100] [TRAIN] Loss: 0.1876 Acc: 0.9884
[Epoch 57/100] [TRAIN] Loss: 0.1738 Acc: 0.9922
[Epoch 58/100] [TRAIN] Loss: 0.1594 Acc: 0.9961
[Epoch 59/100] [TRAIN] Loss: 0.1882 Acc: 0.9884
[Epoch 60/100] [TRAIN] Loss: 0.1808 Acc: 0.9729 [VAL] Loss: 0.7051 Acc: 0.7791
[Epoch 61/100] [TRAIN] Loss: 0.1792 Acc: 0.9729
[Epoch 62/100] [TRAIN] Loss: 0.1492 Acc: 0.9845
[Epoch 63/100] [TRAIN] Loss: 0.1615 Acc: 0.9767
[Epoch 64/100] [TRAIN] Loss: 0.1629 Acc: 0.9845
[Epoch 65/100] [TRAIN] Loss: 0.1489 Acc: 0.9922 [VAL] Loss: 0.6287 Acc: 0.8256
[Epoch 66/100] [TRAIN] Loss: 0.1698 Acc: 0.9767
[Epoch 67/100] [TRAIN] Loss: 0.1339 Acc: 0.9884
[Epoch 68/100] [TRAIN] Loss: 0.1576 Acc: 0.9922
[Epoch 69/100] [TRAIN] Loss: 0.1561 Acc: 0.9845
[Epoch 70/100] [TRAIN] Loss: 0.1266 Acc: 0.9961 [VAL] Loss: 0.8185 Acc: 0.7442
[Epoch 71/100] [TRAIN] Loss: 0.1355 Acc: 0.9806
[Epoch 72/100] [TRAIN] Loss: 0.0976 Acc: 1.0000
[Epoch 73/100] [TRAIN] Loss: 0.1369 Acc: 0.9884
[Epoch 74/100] [TRAIN] Loss: 0.1388 Acc: 0.9884
[Epoch 75/100] [TRAIN] Loss: 0.1087 Acc: 1.0000 [VAL] Loss: 0.8484 Acc: 0.7093
[Epoch 76/100] [TRAIN] Loss: 0.1345 Acc: 0.9767
[Epoch 77/100] [TRAIN] Loss: 0.1309 Acc: 0.9806
[Epoch 78/100] [TRAIN] Loss: 0.1125 Acc: 0.9961
[Epoch 79/100] [TRAIN] Loss: 0.1311 Acc: 0.9884
[Epoch 80/100] [TRAIN] Loss: 0.1020 Acc: 0.9922 [VAL] Loss: 0.4965 Acc: 0.8256
[Epoch 81/100] [TRAIN] Loss: 0.0960 Acc: 0.9922
[Epoch 82/100] [TRAIN] Loss: 0.1339 Acc: 0.9884
[Epoch 83/100] [TRAIN] Loss: 0.1299 Acc: 0.9845
[Epoch 84/100] [TRAIN] Loss: 0.1457 Acc: 0.9767
[Epoch 85/100] [TRAIN] Loss: 0.1035 Acc: 0.9922 [VAL] Loss: 0.4948 Acc: 0.8140
[Epoch 86/100] [TRAIN] Loss: 0.1088 Acc: 0.9922
[Epoch 87/100] [TRAIN] Loss: 0.1309 Acc: 0.9845
[Epoch 88/100] [TRAIN] Loss: 0.0930 Acc: 0.9961
[Epoch 89/100] [TRAIN] Loss: 0.2092 Acc: 0.9574
[Epoch 90/100] [TRAIN] Loss: 0.1491 Acc: 0.9922 [VAL] Loss: 0.8720 Acc: 0.7209
[Epoch 91/100] [TRAIN] Loss: 0.1795 Acc: 0.9690
[Epoch 92/100] [TRAIN] Loss: 0.1241 Acc: 0.9845
[Epoch 93/100] [TRAIN] Loss: 0.1183 Acc: 0.9961
[Epoch 94/100] [TRAIN] Loss: 0.1063 Acc: 1.0000
[Epoch 95/100] [TRAIN] Loss: 0.1102 Acc: 0.9884 [VAL] Loss: 0.4891 Acc: 0.8140
[Epoch 96/100] [TRAIN] Loss: 0.1059 Acc: 0.9884
[Epoch 97/100] [TRAIN] Loss: 0.1130 Acc: 0.9922
[Epoch 98/100] [TRAIN] Loss: 0.1306 Acc: 0.9729
[Epoch 99/100] [TRAIN] Loss: 0.0919 Acc: 1.0000
[Epoch 100/100] [TRAIN] Loss: 0.1237 Acc: 0.9884 [VAL] Loss: 0.9070 Acc: 0.6860
[TEST] Loss: 0.5654 Acc: 0.7558
===================== TRAINING FINISH! ====================

############################################################
#                                                          #
#                  Test Accuracy : 0.7558                  #
#                                                          #
############################################################

