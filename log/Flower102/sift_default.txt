[ DATADIR ]  ./data/102flowers
[ DATASET ] [ train ] N_CLASS: 102 , SIZE: 1020
[ DATASET ] [ val ] N_CLASS: 102 , SIZE: 1020
[ DATASET ] [ test ] N_CLASS: 102 , SIZE: 6149
[ NETWORK ]  resnet18 [N_CV] 1
[ DEVICE  ] CUDA available
[OPTIMIZER] ADAM FIXED [LearningRate]  5e-05

====================== TRAINING START! =====================
[Epoch 1/100] [TRAIN] Loss: 4.5857 Acc: 0.0235
[Epoch 2/100] [TRAIN] Loss: 4.3136 Acc: 0.0608
[Epoch 3/100] [TRAIN] Loss: 4.0871 Acc: 0.1206
[Epoch 4/100] [TRAIN] Loss: 3.8901 Acc: 0.1637
[Epoch 5/100] [TRAIN] Loss: 3.7356 Acc: 0.1843 [VAL] Loss: 3.6663 Acc: 0.1853
[Epoch 6/100] [TRAIN] Loss: 3.5940 Acc: 0.2078
[Epoch 7/100] [TRAIN] Loss: 3.4447 Acc: 0.2588
[Epoch 8/100] [TRAIN] Loss: 3.3390 Acc: 0.2618
[Epoch 9/100] [TRAIN] Loss: 3.2366 Acc: 0.3029
[Epoch 10/100] [TRAIN] Loss: 3.1104 Acc: 0.3039 [VAL] Loss: 3.2467 Acc: 0.2696
[Epoch 11/100] [TRAIN] Loss: 3.0425 Acc: 0.3471
[Epoch 12/100] [TRAIN] Loss: 2.9326 Acc: 0.3529
[Epoch 13/100] [TRAIN] Loss: 2.8687 Acc: 0.3657
[Epoch 14/100] [TRAIN] Loss: 2.7839 Acc: 0.3941
[Epoch 15/100] [TRAIN] Loss: 2.6795 Acc: 0.4176 [VAL] Loss: 3.0043 Acc: 0.2843
[Epoch 16/100] [TRAIN] Loss: 2.6411 Acc: 0.4265
[Epoch 17/100] [TRAIN] Loss: 2.6052 Acc: 0.4353
[Epoch 18/100] [TRAIN] Loss: 2.4919 Acc: 0.4480
[Epoch 19/100] [TRAIN] Loss: 2.4495 Acc: 0.4637
[Epoch 20/100] [TRAIN] Loss: 2.3921 Acc: 0.4627 [VAL] Loss: 2.8041 Acc: 0.3186
[Epoch 21/100] [TRAIN] Loss: 2.3633 Acc: 0.4873
[Epoch 22/100] [TRAIN] Loss: 2.3244 Acc: 0.4637
[Epoch 23/100] [TRAIN] Loss: 2.2720 Acc: 0.4892
[Epoch 24/100] [TRAIN] Loss: 2.1891 Acc: 0.5108
[Epoch 25/100] [TRAIN] Loss: 2.1624 Acc: 0.5118 [VAL] Loss: 2.7351 Acc: 0.3373
[Epoch 26/100] [TRAIN] Loss: 2.1007 Acc: 0.5186
[Epoch 27/100] [TRAIN] Loss: 2.1000 Acc: 0.5412
[Epoch 28/100] [TRAIN] Loss: 2.0119 Acc: 0.5598
[Epoch 29/100] [TRAIN] Loss: 1.9841 Acc: 0.5520
[Epoch 30/100] [TRAIN] Loss: 1.9266 Acc: 0.5647 [VAL] Loss: 2.7200 Acc: 0.3382
[Epoch 31/100] [TRAIN] Loss: 1.9253 Acc: 0.5784
[Epoch 32/100] [TRAIN] Loss: 1.8778 Acc: 0.5814
[Epoch 33/100] [TRAIN] Loss: 1.8531 Acc: 0.5853
[Epoch 34/100] [TRAIN] Loss: 1.8104 Acc: 0.6029
[Epoch 35/100] [TRAIN] Loss: 1.7509 Acc: 0.6235 [VAL] Loss: 2.5961 Acc: 0.3598
[Epoch 36/100] [TRAIN] Loss: 1.7011 Acc: 0.6304
[Epoch 37/100] [TRAIN] Loss: 1.7183 Acc: 0.6186
[Epoch 38/100] [TRAIN] Loss: 1.6295 Acc: 0.6431
[Epoch 39/100] [TRAIN] Loss: 1.6259 Acc: 0.6520
[Epoch 40/100] [TRAIN] Loss: 1.5543 Acc: 0.6755 [VAL] Loss: 2.5560 Acc: 0.3794
[Epoch 41/100] [TRAIN] Loss: 1.5405 Acc: 0.6549
[Epoch 42/100] [TRAIN] Loss: 1.5289 Acc: 0.6608
[Epoch 43/100] [TRAIN] Loss: 1.5071 Acc: 0.6637
[Epoch 44/100] [TRAIN] Loss: 1.4736 Acc: 0.6755
[Epoch 45/100] [TRAIN] Loss: 1.4235 Acc: 0.6882 [VAL] Loss: 2.5589 Acc: 0.3696
[Epoch 46/100] [TRAIN] Loss: 1.4318 Acc: 0.7029
[Epoch 47/100] [TRAIN] Loss: 1.3835 Acc: 0.7020
[Epoch 48/100] [TRAIN] Loss: 1.3462 Acc: 0.7235
[Epoch 49/100] [TRAIN] Loss: 1.3090 Acc: 0.7343
[Epoch 50/100] [TRAIN] Loss: 1.2720 Acc: 0.7373 [VAL] Loss: 2.5056 Acc: 0.3882
[Epoch 51/100] [TRAIN] Loss: 1.2372 Acc: 0.7402
[Epoch 52/100] [TRAIN] Loss: 1.2375 Acc: 0.7490
[Epoch 53/100] [TRAIN] Loss: 1.1886 Acc: 0.7549
[Epoch 54/100] [TRAIN] Loss: 1.1709 Acc: 0.7529
[Epoch 55/100] [TRAIN] Loss: 1.1606 Acc: 0.7647 [VAL] Loss: 2.4993 Acc: 0.3873
[Epoch 56/100] [TRAIN] Loss: 1.1491 Acc: 0.7706
[Epoch 57/100] [TRAIN] Loss: 1.0805 Acc: 0.7863
[Epoch 58/100] [TRAIN] Loss: 1.0964 Acc: 0.7824
[Epoch 59/100] [TRAIN] Loss: 1.0511 Acc: 0.7902
[Epoch 60/100] [TRAIN] Loss: 1.0356 Acc: 0.7961 [VAL] Loss: 2.4674 Acc: 0.3922
[Epoch 61/100] [TRAIN] Loss: 1.0337 Acc: 0.7873
[Epoch 62/100] [TRAIN] Loss: 0.9909 Acc: 0.8098
[Epoch 63/100] [TRAIN] Loss: 0.9828 Acc: 0.7990
[Epoch 64/100] [TRAIN] Loss: 0.9566 Acc: 0.8049
[Epoch 65/100] [TRAIN] Loss: 0.9243 Acc: 0.8186 [VAL] Loss: 2.4835 Acc: 0.3951
[Epoch 66/100] [TRAIN] Loss: 0.8964 Acc: 0.8461
[Epoch 67/100] [TRAIN] Loss: 0.8746 Acc: 0.8422
[Epoch 68/100] [TRAIN] Loss: 0.8648 Acc: 0.8490
[Epoch 69/100] [TRAIN] Loss: 0.8330 Acc: 0.8588
[Epoch 70/100] [TRAIN] Loss: 0.8166 Acc: 0.8608 [VAL] Loss: 2.4463 Acc: 0.4029
[Epoch 71/100] [TRAIN] Loss: 0.7997 Acc: 0.8775
[Epoch 72/100] [TRAIN] Loss: 0.7757 Acc: 0.8725
[Epoch 73/100] [TRAIN] Loss: 0.7980 Acc: 0.8588
[Epoch 74/100] [TRAIN] Loss: 0.7545 Acc: 0.8706
[Epoch 75/100] [TRAIN] Loss: 0.7539 Acc: 0.8716 [VAL] Loss: 2.5080 Acc: 0.4245
[Epoch 76/100] [TRAIN] Loss: 0.6987 Acc: 0.8824
[Epoch 77/100] [TRAIN] Loss: 0.6779 Acc: 0.9069
[Epoch 78/100] [TRAIN] Loss: 0.6750 Acc: 0.9049
[Epoch 79/100] [TRAIN] Loss: 0.6386 Acc: 0.9098
[Epoch 80/100] [TRAIN] Loss: 0.6384 Acc: 0.9176 [VAL] Loss: 2.4348 Acc: 0.4137
[Epoch 81/100] [TRAIN] Loss: 0.6273 Acc: 0.9069
[Epoch 82/100] [TRAIN] Loss: 0.6134 Acc: 0.9127
[Epoch 83/100] [TRAIN] Loss: 0.5961 Acc: 0.9216
[Epoch 84/100] [TRAIN] Loss: 0.5793 Acc: 0.9118
[Epoch 85/100] [TRAIN] Loss: 0.5448 Acc: 0.9275 [VAL] Loss: 2.5849 Acc: 0.4108
[Epoch 86/100] [TRAIN] Loss: 0.5536 Acc: 0.9294
[Epoch 87/100] [TRAIN] Loss: 0.5429 Acc: 0.9284
[Epoch 88/100] [TRAIN] Loss: 0.5263 Acc: 0.9275
[Epoch 89/100] [TRAIN] Loss: 0.5194 Acc: 0.9363
[Epoch 90/100] [TRAIN] Loss: 0.5096 Acc: 0.9363 [VAL] Loss: 2.5271 Acc: 0.3990
[Epoch 91/100] [TRAIN] Loss: 0.5043 Acc: 0.9382
[Epoch 92/100] [TRAIN] Loss: 0.4671 Acc: 0.9520
[Epoch 93/100] [TRAIN] Loss: 0.4554 Acc: 0.9529
[Epoch 94/100] [TRAIN] Loss: 0.4649 Acc: 0.9471
[Epoch 95/100] [TRAIN] Loss: 0.4406 Acc: 0.9471 [VAL] Loss: 2.5357 Acc: 0.4069
[Epoch 96/100] [TRAIN] Loss: 0.4383 Acc: 0.9490
[Epoch 97/100] [TRAIN] Loss: 0.4018 Acc: 0.9549
[Epoch 98/100] [TRAIN] Loss: 0.3877 Acc: 0.9686
[Epoch 99/100] [TRAIN] Loss: 0.4024 Acc: 0.9608
[Epoch 100/100] [TRAIN] Loss: 0.3822 Acc: 0.9569 [VAL] Loss: 2.5139 Acc: 0.4245
[TEST] Loss: 2.7191 Acc: 0.4093
===================== TRAINING FINISH! ====================

############################################################
#                                                          #
#                  Test Accuracy : 0.4093                  #
#                                                          #
############################################################

