[ DATADIR ]  ./data/102flowers
[ AUGMENT ] [resize] 512 [sift] None [edge] None [gabor] None [perspective] None
[ DATASET ] [train] n:102, size:1020 [val] n:102, size:1020 [test] n:102, size:6149
[ NETWORK ] [backbone] resnet18 [n_cv] 0 [gabor] True
[ DEVICE  ] CUDA available
[OPTIMIZER] ADAM FIXED [LearningRate]  5e-05

====================== TRAINING START! =====================
[Epoch 1/100] [TRAIN] Loss: 4.6112 Acc: 0.0167
[Epoch 2/100] [TRAIN] Loss: 4.4605 Acc: 0.0549
[Epoch 3/100] [TRAIN] Loss: 4.3521 Acc: 0.0578
[Epoch 4/100] [TRAIN] Loss: 4.2584 Acc: 0.0873
[Epoch 5/100] [TRAIN] Loss: 4.1789 Acc: 0.1049 [VAL] Loss: 4.2084 Acc: 0.0931
[Epoch 6/100] [TRAIN] Loss: 4.0996 Acc: 0.1265
[Epoch 7/100] [TRAIN] Loss: 4.0622 Acc: 0.1255
[Epoch 8/100] [TRAIN] Loss: 3.9870 Acc: 0.1510
[Epoch 9/100] [TRAIN] Loss: 3.9503 Acc: 0.1490
[Epoch 10/100] [TRAIN] Loss: 3.8926 Acc: 0.1667 [VAL] Loss: 4.0064 Acc: 0.1206
[Epoch 11/100] [TRAIN] Loss: 3.8359 Acc: 0.1686
[Epoch 12/100] [TRAIN] Loss: 3.7933 Acc: 0.1833
[Epoch 13/100] [TRAIN] Loss: 3.7498 Acc: 0.1784
[Epoch 14/100] [TRAIN] Loss: 3.7140 Acc: 0.1804
[Epoch 15/100] [TRAIN] Loss: 3.6708 Acc: 0.1961 [VAL] Loss: 4.2277 Acc: 0.0706
[Epoch 16/100] [TRAIN] Loss: 3.6088 Acc: 0.2176
[Epoch 17/100] [TRAIN] Loss: 3.5770 Acc: 0.2039
[Epoch 18/100] [TRAIN] Loss: 3.5491 Acc: 0.2039
[Epoch 19/100] [TRAIN] Loss: 3.5024 Acc: 0.2284
[Epoch 20/100] [TRAIN] Loss: 3.4750 Acc: 0.2255 [VAL] Loss: 4.3942 Acc: 0.0824
[Epoch 21/100] [TRAIN] Loss: 3.4475 Acc: 0.2324
[Epoch 22/100] [TRAIN] Loss: 3.4139 Acc: 0.2510
[Epoch 23/100] [TRAIN] Loss: 3.3743 Acc: 0.2520
[Epoch 24/100] [TRAIN] Loss: 3.3545 Acc: 0.2520
[Epoch 25/100] [TRAIN] Loss: 3.3309 Acc: 0.2696 [VAL] Loss: 3.6961 Acc: 0.1608
[Epoch 26/100] [TRAIN] Loss: 3.2955 Acc: 0.2657
[Epoch 27/100] [TRAIN] Loss: 3.2573 Acc: 0.2686
[Epoch 28/100] [TRAIN] Loss: 3.2709 Acc: 0.2647
[Epoch 29/100] [TRAIN] Loss: 3.2161 Acc: 0.2824
[Epoch 30/100] [TRAIN] Loss: 3.2071 Acc: 0.2755 [VAL] Loss: 3.9776 Acc: 0.1225
[Epoch 31/100] [TRAIN] Loss: 3.1672 Acc: 0.2873
[Epoch 32/100] [TRAIN] Loss: 3.1227 Acc: 0.3020
[Epoch 33/100] [TRAIN] Loss: 3.1099 Acc: 0.2882
[Epoch 34/100] [TRAIN] Loss: 3.0576 Acc: 0.3245
[Epoch 35/100] [TRAIN] Loss: 3.0217 Acc: 0.3176 [VAL] Loss: 3.6413 Acc: 0.1510
[Epoch 36/100] [TRAIN] Loss: 3.0003 Acc: 0.3382
[Epoch 37/100] [TRAIN] Loss: 2.9965 Acc: 0.3216
[Epoch 38/100] [TRAIN] Loss: 2.9722 Acc: 0.3353
[Epoch 39/100] [TRAIN] Loss: 2.9540 Acc: 0.3127
[Epoch 40/100] [TRAIN] Loss: 2.9232 Acc: 0.3373 [VAL] Loss: 3.5018 Acc: 0.1843
[Epoch 41/100] [TRAIN] Loss: 2.8897 Acc: 0.3451
[Epoch 42/100] [TRAIN] Loss: 2.8906 Acc: 0.3520
[Epoch 43/100] [TRAIN] Loss: 2.8668 Acc: 0.3510
[Epoch 44/100] [TRAIN] Loss: 2.8324 Acc: 0.3422
[Epoch 45/100] [TRAIN] Loss: 2.8209 Acc: 0.3569 [VAL] Loss: 3.4459 Acc: 0.1892
[Epoch 46/100] [TRAIN] Loss: 2.7866 Acc: 0.3745
[Epoch 47/100] [TRAIN] Loss: 2.8031 Acc: 0.3627
[Epoch 48/100] [TRAIN] Loss: 2.7430 Acc: 0.3843
[Epoch 49/100] [TRAIN] Loss: 2.7503 Acc: 0.3745
[Epoch 50/100] [TRAIN] Loss: 2.7033 Acc: 0.3873 [VAL] Loss: 3.6402 Acc: 0.1569
[Epoch 51/100] [TRAIN] Loss: 2.6780 Acc: 0.4010
[Epoch 52/100] [TRAIN] Loss: 2.6729 Acc: 0.3980
[Epoch 53/100] [TRAIN] Loss: 2.6459 Acc: 0.3941
[Epoch 54/100] [TRAIN] Loss: 2.6105 Acc: 0.4118
[Epoch 55/100] [TRAIN] Loss: 2.5906 Acc: 0.4265 [VAL] Loss: 4.5055 Acc: 0.0804
[Epoch 56/100] [TRAIN] Loss: 2.5862 Acc: 0.4176
[Epoch 57/100] [TRAIN] Loss: 2.5872 Acc: 0.4265
[Epoch 58/100] [TRAIN] Loss: 2.5779 Acc: 0.3951
[Epoch 59/100] [TRAIN] Loss: 2.5624 Acc: 0.4206
[Epoch 60/100] [TRAIN] Loss: 2.5354 Acc: 0.4206 [VAL] Loss: 3.4827 Acc: 0.1931
[Epoch 61/100] [TRAIN] Loss: 2.4832 Acc: 0.4500
[Epoch 62/100] [TRAIN] Loss: 2.4589 Acc: 0.4549
[Epoch 63/100] [TRAIN] Loss: 2.4601 Acc: 0.4412
[Epoch 64/100] [TRAIN] Loss: 2.4347 Acc: 0.4510
[Epoch 65/100] [TRAIN] Loss: 2.4164 Acc: 0.4539 [VAL] Loss: 3.5945 Acc: 0.1912
[Epoch 66/100] [TRAIN] Loss: 2.4120 Acc: 0.4627
[Epoch 67/100] [TRAIN] Loss: 2.3759 Acc: 0.4755
[Epoch 68/100] [TRAIN] Loss: 2.3820 Acc: 0.4637
[Epoch 69/100] [TRAIN] Loss: 2.3516 Acc: 0.4833
[Epoch 70/100] [TRAIN] Loss: 2.3396 Acc: 0.4745 [VAL] Loss: 5.7764 Acc: 0.0961
[Epoch 71/100] [TRAIN] Loss: 2.3031 Acc: 0.4824
[Epoch 72/100] [TRAIN] Loss: 2.2856 Acc: 0.5010
[Epoch 73/100] [TRAIN] Loss: 2.2596 Acc: 0.4824
[Epoch 74/100] [TRAIN] Loss: 2.2234 Acc: 0.4922
[Epoch 75/100] [TRAIN] Loss: 2.2443 Acc: 0.5020 [VAL] Loss: 3.6635 Acc: 0.2039
[Epoch 76/100] [TRAIN] Loss: 2.2150 Acc: 0.5049
[Epoch 77/100] [TRAIN] Loss: 2.2225 Acc: 0.4843
[Epoch 78/100] [TRAIN] Loss: 2.1936 Acc: 0.5049
[Epoch 79/100] [TRAIN] Loss: 2.1648 Acc: 0.5186
[Epoch 80/100] [TRAIN] Loss: 2.1378 Acc: 0.5157 [VAL] Loss: 3.6966 Acc: 0.1520
[Epoch 81/100] [TRAIN] Loss: 2.1105 Acc: 0.5245
[Epoch 82/100] [TRAIN] Loss: 2.1169 Acc: 0.5176
[Epoch 83/100] [TRAIN] Loss: 2.0967 Acc: 0.5147
[Epoch 84/100] [TRAIN] Loss: 2.0873 Acc: 0.5333
[Epoch 85/100] [TRAIN] Loss: 2.0451 Acc: 0.5451 [VAL] Loss: 3.3044 Acc: 0.2235
[Epoch 86/100] [TRAIN] Loss: 2.0435 Acc: 0.5490
[Epoch 87/100] [TRAIN] Loss: 2.0625 Acc: 0.5363
[Epoch 88/100] [TRAIN] Loss: 2.0060 Acc: 0.5500
[Epoch 89/100] [TRAIN] Loss: 1.9858 Acc: 0.5539
[Epoch 90/100] [TRAIN] Loss: 1.9842 Acc: 0.5539 [VAL] Loss: 3.1592 Acc: 0.2755
[Epoch 91/100] [TRAIN] Loss: 1.9562 Acc: 0.5618
[Epoch 92/100] [TRAIN] Loss: 2.0136 Acc: 0.5490
[Epoch 93/100] [TRAIN] Loss: 1.9391 Acc: 0.5647
[Epoch 94/100] [TRAIN] Loss: 1.9131 Acc: 0.5657
[Epoch 95/100] [TRAIN] Loss: 1.8741 Acc: 0.5853 [VAL] Loss: 3.1978 Acc: 0.2549
[Epoch 96/100] [TRAIN] Loss: 1.8870 Acc: 0.5971
[Epoch 97/100] [TRAIN] Loss: 1.8828 Acc: 0.5814
[Epoch 98/100] [TRAIN] Loss: 1.8864 Acc: 0.5696
[Epoch 99/100] [TRAIN] Loss: 1.8318 Acc: 0.5931
[Epoch 100/100] [TRAIN] Loss: 1.8374 Acc: 0.5814 [VAL] Loss: 3.6874 Acc: 0.1971
[TEST] Loss: 3.8904 Acc: 0.2132
===================== TRAINING FINISH! ====================

############################################################
#                                                          #
#                  Test Accuracy : 0.2132                  #
#                                                          #
############################################################

