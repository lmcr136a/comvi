[ DATADIR ]  ./data/102flowers
[ DATASET ] [ train ] N_CLASS: 102 , SIZE: 1020
[ DATASET ] [ val ] N_CLASS: 102 , SIZE: 1020
[ DATASET ] [ test ] N_CLASS: 102 , SIZE: 6149
[ NETWORK ]  resnet18 [N_CV] 1
[ DEVICE  ] CUDA available
[OPTIMIZER] ADAM FIXED [LearningRate]  5e-05

====================== TRAINING START! =====================
[Epoch 1/100] [TRAIN] Loss: 4.5684 Acc: 0.0343
[Epoch 2/100] [TRAIN] Loss: 4.2721 Acc: 0.0912
[Epoch 3/100] [TRAIN] Loss: 4.0386 Acc: 0.1275
[Epoch 4/100] [TRAIN] Loss: 3.8575 Acc: 0.1647
[Epoch 5/100] [TRAIN] Loss: 3.6911 Acc: 0.1931 [VAL] Loss: 3.6483 Acc: 0.1804
[Epoch 6/100] [TRAIN] Loss: 3.5502 Acc: 0.2078
[Epoch 7/100] [TRAIN] Loss: 3.4243 Acc: 0.2441
[Epoch 8/100] [TRAIN] Loss: 3.3096 Acc: 0.2657
[Epoch 9/100] [TRAIN] Loss: 3.2139 Acc: 0.2951
[Epoch 10/100] [TRAIN] Loss: 3.1216 Acc: 0.3186 [VAL] Loss: 3.2176 Acc: 0.2696
[Epoch 11/100] [TRAIN] Loss: 3.0230 Acc: 0.3108
[Epoch 12/100] [TRAIN] Loss: 2.9510 Acc: 0.3490
[Epoch 13/100] [TRAIN] Loss: 2.8920 Acc: 0.3706
[Epoch 14/100] [TRAIN] Loss: 2.8175 Acc: 0.3843
[Epoch 15/100] [TRAIN] Loss: 2.7112 Acc: 0.4118 [VAL] Loss: 3.0543 Acc: 0.2775
[Epoch 16/100] [TRAIN] Loss: 2.7004 Acc: 0.3863
[Epoch 17/100] [TRAIN] Loss: 2.5884 Acc: 0.4324
[Epoch 18/100] [TRAIN] Loss: 2.5291 Acc: 0.4529
[Epoch 19/100] [TRAIN] Loss: 2.4936 Acc: 0.4510
[Epoch 20/100] [TRAIN] Loss: 2.4130 Acc: 0.4735 [VAL] Loss: 2.8769 Acc: 0.3225
[Epoch 21/100] [TRAIN] Loss: 2.3888 Acc: 0.4647
[Epoch 22/100] [TRAIN] Loss: 2.3147 Acc: 0.4765
[Epoch 23/100] [TRAIN] Loss: 2.2607 Acc: 0.5167
[Epoch 24/100] [TRAIN] Loss: 2.2321 Acc: 0.5078
[Epoch 25/100] [TRAIN] Loss: 2.1776 Acc: 0.5078 [VAL] Loss: 2.7546 Acc: 0.3382
[Epoch 26/100] [TRAIN] Loss: 2.1211 Acc: 0.5373
[Epoch 27/100] [TRAIN] Loss: 2.0816 Acc: 0.5500
[Epoch 28/100] [TRAIN] Loss: 2.0319 Acc: 0.5706
[Epoch 29/100] [TRAIN] Loss: 1.9930 Acc: 0.5618
[Epoch 30/100] [TRAIN] Loss: 1.9617 Acc: 0.5716 [VAL] Loss: 2.7463 Acc: 0.3559
[Epoch 31/100] [TRAIN] Loss: 1.9228 Acc: 0.5755
[Epoch 32/100] [TRAIN] Loss: 1.8759 Acc: 0.5853
[Epoch 33/100] [TRAIN] Loss: 1.8208 Acc: 0.5902
[Epoch 34/100] [TRAIN] Loss: 1.8059 Acc: 0.5980
[Epoch 35/100] [TRAIN] Loss: 1.7952 Acc: 0.5843 [VAL] Loss: 2.5888 Acc: 0.3804
[Epoch 36/100] [TRAIN] Loss: 1.7170 Acc: 0.6225
[Epoch 37/100] [TRAIN] Loss: 1.6925 Acc: 0.6314
[Epoch 38/100] [TRAIN] Loss: 1.6503 Acc: 0.6451
[Epoch 39/100] [TRAIN] Loss: 1.6140 Acc: 0.6422
[Epoch 40/100] [TRAIN] Loss: 1.5850 Acc: 0.6510 [VAL] Loss: 2.6565 Acc: 0.3480
[Epoch 41/100] [TRAIN] Loss: 1.5990 Acc: 0.6422
[Epoch 42/100] [TRAIN] Loss: 1.5583 Acc: 0.6676
[Epoch 43/100] [TRAIN] Loss: 1.5108 Acc: 0.6784
[Epoch 44/100] [TRAIN] Loss: 1.4419 Acc: 0.6843
[Epoch 45/100] [TRAIN] Loss: 1.4696 Acc: 0.6765 [VAL] Loss: 2.5719 Acc: 0.3706
[Epoch 46/100] [TRAIN] Loss: 1.3922 Acc: 0.7088
[Epoch 47/100] [TRAIN] Loss: 1.3452 Acc: 0.7118
[Epoch 48/100] [TRAIN] Loss: 1.3425 Acc: 0.7127
[Epoch 49/100] [TRAIN] Loss: 1.3227 Acc: 0.7324
[Epoch 50/100] [TRAIN] Loss: 1.3161 Acc: 0.7186 [VAL] Loss: 2.5076 Acc: 0.4059
[Epoch 51/100] [TRAIN] Loss: 1.2803 Acc: 0.7235
[Epoch 52/100] [TRAIN] Loss: 1.2326 Acc: 0.7549
[Epoch 53/100] [TRAIN] Loss: 1.2083 Acc: 0.7441
[Epoch 54/100] [TRAIN] Loss: 1.1961 Acc: 0.7480
[Epoch 55/100] [TRAIN] Loss: 1.1511 Acc: 0.7647 [VAL] Loss: 2.5424 Acc: 0.3941
[Epoch 56/100] [TRAIN] Loss: 1.1298 Acc: 0.7853
[Epoch 57/100] [TRAIN] Loss: 1.1132 Acc: 0.7873
[Epoch 58/100] [TRAIN] Loss: 1.1099 Acc: 0.7686
[Epoch 59/100] [TRAIN] Loss: 1.0977 Acc: 0.7765
[Epoch 60/100] [TRAIN] Loss: 1.0313 Acc: 0.8020 [VAL] Loss: 2.4867 Acc: 0.4049
[Epoch 61/100] [TRAIN] Loss: 1.0318 Acc: 0.7931
[Epoch 62/100] [TRAIN] Loss: 1.0129 Acc: 0.7882
[Epoch 63/100] [TRAIN] Loss: 0.9688 Acc: 0.8069
[Epoch 64/100] [TRAIN] Loss: 0.9462 Acc: 0.8206
[Epoch 65/100] [TRAIN] Loss: 0.9330 Acc: 0.8333 [VAL] Loss: 2.4964 Acc: 0.4127
[Epoch 66/100] [TRAIN] Loss: 0.8785 Acc: 0.8461
[Epoch 67/100] [TRAIN] Loss: 0.8675 Acc: 0.8569
[Epoch 68/100] [TRAIN] Loss: 0.8500 Acc: 0.8461
[Epoch 69/100] [TRAIN] Loss: 0.8368 Acc: 0.8539
[Epoch 70/100] [TRAIN] Loss: 0.8062 Acc: 0.8647 [VAL] Loss: 2.5537 Acc: 0.4010
[Epoch 71/100] [TRAIN] Loss: 0.7679 Acc: 0.8657
[Epoch 72/100] [TRAIN] Loss: 0.7529 Acc: 0.8833
[Epoch 73/100] [TRAIN] Loss: 0.7359 Acc: 0.8843
[Epoch 74/100] [TRAIN] Loss: 0.7350 Acc: 0.8853
[Epoch 75/100] [TRAIN] Loss: 0.7113 Acc: 0.8882 [VAL] Loss: 2.5102 Acc: 0.4118
[Epoch 76/100] [TRAIN] Loss: 0.7096 Acc: 0.8873
[Epoch 77/100] [TRAIN] Loss: 0.7148 Acc: 0.8824
[Epoch 78/100] [TRAIN] Loss: 0.6729 Acc: 0.8833
[Epoch 79/100] [TRAIN] Loss: 0.6531 Acc: 0.8941
[Epoch 80/100] [TRAIN] Loss: 0.6493 Acc: 0.8941 [VAL] Loss: 2.5439 Acc: 0.4137
[Epoch 81/100] [TRAIN] Loss: 0.6157 Acc: 0.9167
[Epoch 82/100] [TRAIN] Loss: 0.6140 Acc: 0.9098
[Epoch 83/100] [TRAIN] Loss: 0.5950 Acc: 0.9137
[Epoch 84/100] [TRAIN] Loss: 0.5662 Acc: 0.9157
[Epoch 85/100] [TRAIN] Loss: 0.5813 Acc: 0.9235 [VAL] Loss: 2.5036 Acc: 0.4186
[Epoch 86/100] [TRAIN] Loss: 0.5081 Acc: 0.9422
[Epoch 87/100] [TRAIN] Loss: 0.5258 Acc: 0.9431
[Epoch 88/100] [TRAIN] Loss: 0.5068 Acc: 0.9373
[Epoch 89/100] [TRAIN] Loss: 0.5153 Acc: 0.9284
[Epoch 90/100] [TRAIN] Loss: 0.4990 Acc: 0.9373 [VAL] Loss: 2.7077 Acc: 0.3912
[Epoch 91/100] [TRAIN] Loss: 0.4727 Acc: 0.9471
[Epoch 92/100] [TRAIN] Loss: 0.5034 Acc: 0.9392
[Epoch 93/100] [TRAIN] Loss: 0.4401 Acc: 0.9608
[Epoch 94/100] [TRAIN] Loss: 0.4381 Acc: 0.9578
[Epoch 95/100] [TRAIN] Loss: 0.4227 Acc: 0.9618 [VAL] Loss: 2.5552 Acc: 0.4167
[Epoch 96/100] [TRAIN] Loss: 0.4224 Acc: 0.9529
[Epoch 97/100] [TRAIN] Loss: 0.4028 Acc: 0.9598
[Epoch 98/100] [TRAIN] Loss: 0.4183 Acc: 0.9539
[Epoch 99/100] [TRAIN] Loss: 0.4144 Acc: 0.9588
[Epoch 100/100] [TRAIN] Loss: 0.3457 Acc: 0.9706 [VAL] Loss: 2.5342 Acc: 0.4324
[TEST] Loss: 2.7228 Acc: 0.4061
===================== TRAINING FINISH! ====================

############################################################
#                                                          #
#                  Test Accuracy : 0.4061                  #
#                                                          #
############################################################

